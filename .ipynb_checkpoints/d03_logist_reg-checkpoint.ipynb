{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bbf0287-4580-49df-bc8c-8855a2e323f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import seaborn as sbn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5f88b5-bae6-4eba-8a61-c13c8c7d3775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2415146e-caf9-46f9-9697-40bba4dbd36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05622091-4525-4595-bff4-da5c91d891bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logistic import Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "527b10ef-f58e-46f6-b744-660a832194b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from optimizegrouping import OptmizeGrouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c4b080c-8298-49f4-8f1c-a2d6193cf25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/amex_sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "418b9402-2403-406f-86b6-d7628f810014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>D_44</th>\n",
       "      <th>B_4</th>\n",
       "      <th>D_45</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_46</th>\n",
       "      <th>D_47</th>\n",
       "      <th>D_48</th>\n",
       "      <th>D_49</th>\n",
       "      <th>B_6</th>\n",
       "      <th>B_7</th>\n",
       "      <th>B_8</th>\n",
       "      <th>D_50</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>D_52</th>\n",
       "      <th>P_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>D_53</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>D_54</th>\n",
       "      <th>R_4</th>\n",
       "      <th>S_7</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>D_55</th>\n",
       "      <th>D_56</th>\n",
       "      <th>B_13</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>S_9</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_59</th>\n",
       "      <th>D_60</th>\n",
       "      <th>D_61</th>\n",
       "      <th>B_15</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_62</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_16</th>\n",
       "      <th>B_17</th>\n",
       "      <th>B_18</th>\n",
       "      <th>B_19</th>\n",
       "      <th>B_20</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_69</th>\n",
       "      <th>B_22</th>\n",
       "      <th>D_70</th>\n",
       "      <th>D_71</th>\n",
       "      <th>D_72</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>D_73</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_74</th>\n",
       "      <th>D_75</th>\n",
       "      <th>D_76</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>D_77</th>\n",
       "      <th>B_25</th>\n",
       "      <th>B_26</th>\n",
       "      <th>D_78</th>\n",
       "      <th>D_79</th>\n",
       "      <th>R_8</th>\n",
       "      <th>R_9</th>\n",
       "      <th>S_16</th>\n",
       "      <th>D_80</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>B_27</th>\n",
       "      <th>D_81</th>\n",
       "      <th>D_82</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>D_83</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>D_84</th>\n",
       "      <th>R_16</th>\n",
       "      <th>B_29</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>D_87</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>D_88</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>B_33</th>\n",
       "      <th>D_89</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_91</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_23</th>\n",
       "      <th>S_24</th>\n",
       "      <th>S_25</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>D_103</th>\n",
       "      <th>D_104</th>\n",
       "      <th>D_105</th>\n",
       "      <th>D_106</th>\n",
       "      <th>D_107</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>R_26</th>\n",
       "      <th>R_27</th>\n",
       "      <th>D_108</th>\n",
       "      <th>D_109</th>\n",
       "      <th>D_110</th>\n",
       "      <th>D_111</th>\n",
       "      <th>B_39</th>\n",
       "      <th>D_112</th>\n",
       "      <th>B_40</th>\n",
       "      <th>S_27</th>\n",
       "      <th>D_113</th>\n",
       "      <th>D_115</th>\n",
       "      <th>D_118</th>\n",
       "      <th>D_119</th>\n",
       "      <th>D_121</th>\n",
       "      <th>D_122</th>\n",
       "      <th>D_123</th>\n",
       "      <th>D_124</th>\n",
       "      <th>D_125</th>\n",
       "      <th>D_127</th>\n",
       "      <th>D_128</th>\n",
       "      <th>D_129</th>\n",
       "      <th>B_41</th>\n",
       "      <th>B_42</th>\n",
       "      <th>D_130</th>\n",
       "      <th>D_131</th>\n",
       "      <th>D_132</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_134</th>\n",
       "      <th>D_135</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>B_30</th>\n",
       "      <th>B_38</th>\n",
       "      <th>D_114</th>\n",
       "      <th>D_116</th>\n",
       "      <th>D_117</th>\n",
       "      <th>D_120</th>\n",
       "      <th>D_126</th>\n",
       "      <th>D_63</th>\n",
       "      <th>D_64</th>\n",
       "      <th>D_66</th>\n",
       "      <th>D_68</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.934745</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>1.007647</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.070793</td>\n",
       "      <td>0.740102</td>\n",
       "      <td>0.231717</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>0.420521</td>\n",
       "      <td>0.539715</td>\n",
       "      <td>0.192376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.149564</td>\n",
       "      <td>0.058425</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.153461</td>\n",
       "      <td>0.673522</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.203524</td>\n",
       "      <td>0.629392</td>\n",
       "      <td>0.326101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034643</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>1.008097</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.105671</td>\n",
       "      <td>0.112294</td>\n",
       "      <td>0.488232</td>\n",
       "      <td>0.187285</td>\n",
       "      <td>0.166636</td>\n",
       "      <td>0.100107</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.063465</td>\n",
       "      <td>0.258461</td>\n",
       "      <td>0.227637</td>\n",
       "      <td>0.014553</td>\n",
       "      <td>0.402246</td>\n",
       "      <td>0.446568</td>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.007897</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.184036</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.686719</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>0.377991</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>0.304625</td>\n",
       "      <td>0.040367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006564</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>0.421334</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.208253</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>0.507423</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>1.002178</td>\n",
       "      <td>0.084745</td>\n",
       "      <td>0.006099</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.008099</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>1.007528</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>1.006011</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.005909</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.917811</td>\n",
       "      <td>0.131801</td>\n",
       "      <td>0.936067</td>\n",
       "      <td>0.971994</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.943340</td>\n",
       "      <td>1.002457</td>\n",
       "      <td>1.014510</td>\n",
       "      <td>1.073985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671683</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>0.008676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009372</td>\n",
       "      <td>0.100454</td>\n",
       "      <td>0.928955</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.255787</td>\n",
       "      <td>0.260255</td>\n",
       "      <td>0.256656</td>\n",
       "      <td>0.719791</td>\n",
       "      <td>0.433844</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.684978</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>1.008338</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>1.008523</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CR</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>0.178126</td>\n",
       "      <td>0.034684</td>\n",
       "      <td>1.004028</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060646</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.020626</td>\n",
       "      <td>0.266275</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.438828</td>\n",
       "      <td>0.402195</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.167634</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.339683</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>0.102036</td>\n",
       "      <td>0.242366</td>\n",
       "      <td>0.570898</td>\n",
       "      <td>0.297130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043929</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>1.002821</td>\n",
       "      <td>0.003283</td>\n",
       "      <td>0.208516</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.406434</td>\n",
       "      <td>0.036112</td>\n",
       "      <td>0.748383</td>\n",
       "      <td>0.017684</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.127805</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.212538</td>\n",
       "      <td>0.411989</td>\n",
       "      <td>0.048978</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>0.363754</td>\n",
       "      <td>0.233980</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003602</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.192371</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.287101</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>0.007636</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.007636</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.304711</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.007925</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.227755</td>\n",
       "      <td>0.021153</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.009664</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>1.008568</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.006669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>0.007052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.008645</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>1.000766</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.920889</td>\n",
       "      <td>0.132865</td>\n",
       "      <td>0.930629</td>\n",
       "      <td>0.977674</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007774</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>0.032899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.007599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006547</td>\n",
       "      <td>0.019811</td>\n",
       "      <td>0.292214</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>0.454329</td>\n",
       "      <td>0.446036</td>\n",
       "      <td>0.436884</td>\n",
       "      <td>0.551341</td>\n",
       "      <td>0.286821</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.136650</td>\n",
       "      <td>0.009314</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CO</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0.880875</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.812650</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.031044</td>\n",
       "      <td>0.251598</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.433713</td>\n",
       "      <td>0.339125</td>\n",
       "      <td>0.080370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.183628</td>\n",
       "      <td>0.026981</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.342118</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.202159</td>\n",
       "      <td>0.628938</td>\n",
       "      <td>0.296313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>1.002366</td>\n",
       "      <td>1.005992</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>0.098963</td>\n",
       "      <td>0.209386</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006699</td>\n",
       "      <td>0.213039</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>0.137834</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.280417</td>\n",
       "      <td>0.438647</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004080</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.190958</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>0.015025</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.506746</td>\n",
       "      <td>0.020228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>0.407122</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.006786</td>\n",
       "      <td>0.006549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>1.004567</td>\n",
       "      <td>0.030023</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.003245</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.009829</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>1.000779</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.009410</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>0.302868</td>\n",
       "      <td>0.132692</td>\n",
       "      <td>0.086479</td>\n",
       "      <td>0.972368</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.007076</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.388621</td>\n",
       "      <td>0.368051</td>\n",
       "      <td>0.369018</td>\n",
       "      <td>0.444615</td>\n",
       "      <td>0.149832</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.275856</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007383</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CO</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0.621776</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.012564</td>\n",
       "      <td>1.006183</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046104</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.007235</td>\n",
       "      <td>0.085103</td>\n",
       "      <td>0.118818</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.410723</td>\n",
       "      <td>0.414224</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.174331</td>\n",
       "      <td>0.011969</td>\n",
       "      <td>1.005561</td>\n",
       "      <td>0.430318</td>\n",
       "      <td>0.333342</td>\n",
       "      <td>0.020526</td>\n",
       "      <td>0.204338</td>\n",
       "      <td>0.198356</td>\n",
       "      <td>0.672080</td>\n",
       "      <td>0.411625</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>1.004073</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>0.279464</td>\n",
       "      <td>0.074835</td>\n",
       "      <td>0.170538</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.554483</td>\n",
       "      <td>0.055897</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.009294</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>0.509411</td>\n",
       "      <td>0.394758</td>\n",
       "      <td>0.026844</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.368774</td>\n",
       "      <td>0.434503</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>0.089177</td>\n",
       "      <td>1.007434</td>\n",
       "      <td>1.007289</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>0.054633</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.423241</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.508872</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>0.401139</td>\n",
       "      <td>0.014266</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>0.005918</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.507283</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>1.009117</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.507532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.007541</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>1.009480</td>\n",
       "      <td>0.008491</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.509612</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.009486</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.931634</td>\n",
       "      <td>0.132833</td>\n",
       "      <td>0.957105</td>\n",
       "      <td>0.974041</td>\n",
       "      <td>0.043710</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003711</td>\n",
       "      <td>0.031024</td>\n",
       "      <td>0.680603</td>\n",
       "      <td>0.205291</td>\n",
       "      <td>0.059353</td>\n",
       "      <td>0.058773</td>\n",
       "      <td>0.062736</td>\n",
       "      <td>0.629147</td>\n",
       "      <td>0.290245</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.594160</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>1.002652</td>\n",
       "      <td>1.001869</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CO</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.815746</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.176403</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044671</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.269407</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.465525</td>\n",
       "      <td>0.480303</td>\n",
       "      <td>0.325121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048857</td>\n",
       "      <td>0.159818</td>\n",
       "      <td>1.005185</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.253811</td>\n",
       "      <td>0.570419</td>\n",
       "      <td>0.125195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>1.007410</td>\n",
       "      <td>1.007116</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.122915</td>\n",
       "      <td>0.013041</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.254067</td>\n",
       "      <td>0.183075</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>0.008859</td>\n",
       "      <td>0.382744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.488844</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>0.600739</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.326776</td>\n",
       "      <td>0.422841</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.531486</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>0.185639</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.009251</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.009727</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.503735</td>\n",
       "      <td>0.145214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.144073</td>\n",
       "      <td>0.142552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009507</td>\n",
       "      <td>0.006455</td>\n",
       "      <td>0.392566</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>0.007474</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.006559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007571</td>\n",
       "      <td>0.407653</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007245</td>\n",
       "      <td>1.008890</td>\n",
       "      <td>0.250254</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.007172</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.007841</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.003116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>1.007604</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>0.006960</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.297843</td>\n",
       "      <td>0.132099</td>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.971905</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.589246</td>\n",
       "      <td>1.004867</td>\n",
       "      <td>0.963496</td>\n",
       "      <td>0.809463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006895</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.008149</td>\n",
       "      <td>0.116816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.448481</td>\n",
       "      <td>0.442338</td>\n",
       "      <td>0.436173</td>\n",
       "      <td>0.565815</td>\n",
       "      <td>0.435161</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>0.181963</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>1.006172</td>\n",
       "      <td>1.008584</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006119</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008154</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CO</td>\n",
       "      <td>O</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID       P_2      D_39       B_1       B_2       R_1       S_3      D_41       B_3  D_42      D_43      D_44       B_4      D_45       B_5       R_2      D_46      D_47      D_48  D_49       B_6       B_7       B_8      D_50      D_51       B_9       R_3      D_52       P_3      B_10      D_53       S_5      B_11       S_6      D_54       R_4       S_7      B_12       S_8      D_55      D_56      B_13       R_5      D_58       S_9      B_14      D_59      D_60      D_61      B_15      S_11      D_62      D_65      B_16      B_17      B_18      B_19      B_20      S_12       R_6      S_13      B_21      D_69      B_22      D_70      D_71      D_72      S_15      B_23  D_73       P_4      D_74      D_75  D_76      B_24       R_7      D_77      B_25      B_26      D_78      D_79       R_8  R_9      S_16      D_80      R_10      R_11      B_27      D_81      D_82      S_17      R_12      B_28      R_13      D_83      R_14      R_15  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.934745  0.009119  0.009382  1.007647  0.006104  0.135021  0.001604  0.007174   NaN       NaN  0.003258  0.070793  0.740102  0.231717  0.008309  0.420521  0.539715  0.192376   NaN  0.149564  0.058425  0.002927  0.153461  0.673522  0.009535  0.000085  0.203524  0.629392  0.326101       NaN  0.034643  0.010260  0.001770  1.008097  0.008517  0.105671  0.112294  0.488232  0.187285  0.166636  0.100107  0.009444  0.007174  0.007397  0.010239  0.063465  0.258461  0.227637  0.014553  0.402246  0.446568  0.008656  0.006408       NaN  1.007897  0.005274  0.007630  0.184036  0.003945  0.686719  0.005375  0.005469  0.008050  0.008254  0.377991  0.006970  0.304625  0.040367   NaN  0.006564  0.001298  0.001352   NaN  0.002230  0.009162  0.421334  0.006475  0.001068  0.000747  0.002193  0.006345  NaN  0.000026  0.208253  0.001057  0.009351  0.007236  0.009177  0.507423  0.006550  1.002178  0.084745  0.006099  0.000013  0.002902  0.001115   \n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...  0.880519  0.178126  0.034684  1.004028  0.006911  0.165509  0.005552  0.005068   NaN  0.060646  0.008781  0.020626  0.266275  0.027000  0.004976  0.438828  0.402195  0.014696   NaN  0.167634  0.028411  0.000974       NaN  0.339683  0.012926  0.102036  0.242366  0.570898  0.297130       NaN  0.043929  0.014570  0.002911  1.002821  0.003283  0.208516  0.019050  0.406434  0.036112  0.748383  0.017684  0.005880  0.009756  0.127805  0.018667  0.212538  0.411989  0.048978  0.009538  0.363754  0.233980  0.008747  0.002940       NaN  1.003602  0.008047  0.004319  0.192371  0.007744  0.287101  0.006190  0.007636  0.006174  0.000883  0.007636  0.001278  0.304711  0.014705   NaN  0.004659  0.007925  0.009600   NaN  0.002383  0.008256  0.227755  0.021153  0.000182  0.001542  0.009117  0.006892  NaN  0.006931  0.002119  0.002046  0.009664  0.005375  0.005009       NaN  0.005414  1.008568  0.019672  0.006197  0.005370  0.006271  0.009911   \n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...  0.880875  0.009704  0.004284  0.812650  0.006450       NaN  0.003796  0.007196   NaN       NaN  0.000628  0.031044  0.251598  0.001557  0.001687  0.433713  0.339125  0.080370   NaN  0.183628  0.026981  0.000247       NaN  0.342118  0.009392  0.006264  0.202159  0.628938  0.296313       NaN  0.001824  0.005092  1.002366  1.005992  0.001983       NaN  0.007158  0.009188  0.098963  0.209386  0.001749  0.003000  0.002847       NaN  0.006699  0.213039  0.002820  0.137834  0.006031  0.280417  0.438647  0.000845  0.007836       NaN  1.004080  0.005951  0.002835  0.190958  0.008575  0.006706  0.000036  0.009486  0.002793  0.006101  0.015025  0.008889  0.506746  0.020228   NaN  0.002699  0.002067  0.003329   NaN  0.000552  0.006740  0.407122  0.007427  0.009752  0.002990  0.006786  0.006549  NaN  0.009305  0.000931  0.006391  0.005349  0.005475  0.000167       NaN  0.000159  1.004567  0.030023  0.005352  0.003245  0.002310  0.005328   \n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...  0.621776  0.001083  0.012564  1.006183  0.007829  0.287766  0.004532  0.009937   NaN  0.046104  0.007792  0.007235  0.085103  0.118818  0.004238  0.410723  0.414224  0.013057   NaN  0.174331  0.011969  1.005561  0.430318  0.333342  0.020526  0.204338  0.198356  0.672080  0.411625  0.001379  0.022970  0.005491  0.001113  1.004073  0.008534  0.279464  0.074835  0.170538  0.021400  0.554483  0.055897  0.001347  0.009294  0.011429  0.017101  0.509411  0.394758  0.026844  0.002199  0.368774  0.434503  0.008578  0.089177  1.007434  1.007289  0.007715  0.008557  0.054633  0.000952  0.423241  0.004447  0.004894  0.000993  0.006015  0.010685  0.006446  0.508872  0.005060   NaN  0.007902  0.004011  0.005505   NaN  0.008794  0.006096  0.401139  0.014266  0.004983  0.007304  0.000659  0.005665  NaN  0.006713  0.005918  0.007501  0.507283  0.007924  0.008404       NaN  0.007657  1.009117  0.010497  0.005440  0.001881  0.006133  0.001680   \n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...  0.871900  0.005573  0.007679  0.815746  0.001247  0.176403  0.000231  0.005528   NaN  0.044671  0.002436  0.269407  0.069952  0.004855  0.001991  0.465525  0.480303  0.325121   NaN  0.048857  0.159818  1.005185  0.095238  0.003557  0.004027  0.000050  0.253811  0.570419  0.125195       NaN  0.009350  0.001001  1.007410  1.007116  0.001858  0.122915  0.013041  0.008594  0.254067  0.183075  0.006051  0.008859  0.382744       NaN  0.009469  0.488844  0.002670  0.600739  0.005842  0.326776  0.422841  0.001734  0.005095       NaN  0.531486  0.006706  0.008807  0.185639  0.003575  0.009251  0.009527  0.008175  0.009727  0.001121  0.016457  0.001375  0.503735  0.145214   NaN  0.009202  0.144073  0.142552   NaN  0.009507  0.006455  0.392566  0.009528  0.005802  0.007474  0.005898  0.006559  NaN  0.007571  0.407653  0.005454  0.009085  0.001414  0.003912       NaN  0.007245  1.008890  0.250254  0.000740  0.007172  0.006752  0.000947   \n",
       "\n",
       "       D_84      R_16  B_29      S_18      D_86  D_87      R_17      R_18  D_88  B_31      S_19      R_19      B_32      S_20      R_20      R_21      B_33      D_89      R_22      R_23      D_91      D_92      D_93      D_94      R_24      R_25      D_96      S_22      S_23      S_24      S_25      S_26     D_102     D_103     D_104     D_105  D_106     D_107      B_36      B_37  R_26      R_27  D_108     D_109  D_110  D_111  B_39     D_112      B_40      S_27     D_113     D_115     D_118     D_119     D_121     D_122     D_123     D_124     D_125     D_127     D_128     D_129      B_41  B_42     D_130     D_131  D_132     D_133      R_28  D_134  D_135  D_136  D_137  D_138     D_139     D_140     D_141  D_142     D_143     D_144     D_145  B_30  B_38  D_114  D_116  D_117  D_120  D_126 D_63 D_64  D_66  D_68  target  \n",
       "0  0.001911  0.003256   NaN  0.001277  0.009968   NaN  0.002330  0.002517   NaN     1  0.003511  0.008099  0.007645  0.009411  0.006355  0.008501  1.007528  0.004638  0.001445  0.003080  1.006011  0.003641  0.004638  0.003866  0.005909  0.005458  0.001190  0.917811  0.131801  0.936067  0.971994  0.001281  0.943340  1.002457  1.014510  1.073985    NaN  0.671683  0.007441  0.008676   NaN  1.006130    NaN  0.000226    NaN    NaN   NaN  1.009372  0.100454  0.928955  0.003658  0.255787  0.260255  0.256656  0.719791  0.433844  0.003580  0.684978  0.008398  1.008338  0.999737  1.008523  0.003973   NaN  0.004186  0.005702    NaN  0.006210  0.002715    NaN    NaN    NaN    NaN    NaN  0.007186  0.004234  0.005086    NaN  0.005810  0.002970  0.008533   0.0   2.0    1.0    0.0    4.0    0.0    1.0   CR    O   NaN   6.0       0  \n",
       "1  0.000983  0.006669   NaN  0.009298  0.006460   NaN  0.006503  0.007052   NaN     1  0.005091  0.001838  0.008645  0.009467  0.003500  0.000473  1.000766  0.004864  0.000907  0.003830  0.009166  0.004641  0.000195  0.000523  0.006421  0.004975  0.002397  0.920889  0.132865  0.930629  0.977674  0.003213  0.001621  0.008952  0.004363       NaN    NaN  0.007774  0.007457  0.032899   NaN  1.007599    NaN  0.004743    NaN    NaN   NaN  1.006547  0.019811  0.292214  0.009312  0.454329  0.446036  0.436884  0.551341  0.286821  0.008603  0.136650  0.009314  0.000229  0.999252  0.001777  0.002943   NaN  0.002202  0.001928    NaN  0.002996  0.001701    NaN    NaN    NaN    NaN    NaN  0.002980  0.007479  0.007870    NaN  0.003284  0.003169  0.008514   0.0   2.0    1.0    0.0   -1.0    0.0    1.0   CO    O   NaN   6.0       0  \n",
       "2  0.009366  0.006171   NaN  0.001763  0.004081   NaN  0.005628  0.003440   NaN     1  0.006258  0.009829  0.001252  0.009926  0.004965  0.008178  1.000779  0.004868  0.004085  0.001122  0.009410  0.002195  0.003562  0.003742  0.000170  0.004746  0.009617  0.302868  0.132692  0.086479  0.972368  0.004705  0.009786  0.003091  0.005433       NaN    NaN  0.000847  0.005196  0.004723   NaN  1.003010    NaN  0.009816    NaN    NaN   NaN  1.007076  0.024902       NaN  0.000257  0.388621  0.368051  0.369018  0.444615  0.149832  0.004057  0.275856  0.004732  0.009514  0.008331  0.004189  0.004133   NaN  0.002654  0.003470    NaN  0.009881  0.007691    NaN    NaN    NaN    NaN    NaN  0.007383  0.006623  0.000964    NaN  0.002202  0.000834  0.003444   0.0   1.0    1.0    0.0   -1.0    0.0    1.0   CO    R   NaN   6.0       0  \n",
       "3  0.005498  0.507532   NaN  0.000482  0.001864   NaN  0.000843  0.009902   NaN     1  0.005235  0.008212  0.007541  0.007374  0.009349  0.002196  1.009480  0.008491  0.003347  0.005297  0.509612  0.002310  0.009715  0.003028  0.009486  0.008072  0.006325  0.931634  0.132833  0.957105  0.974041  0.043710  0.002448  0.002433  0.004051       NaN    NaN  0.008019  0.004745  0.007375   NaN  1.004479    NaN  0.008627    NaN    NaN   NaN  1.003711  0.031024  0.680603  0.205291  0.059353  0.058773  0.062736  0.629147  0.290245  0.009977  0.594160  0.004466  0.009322  1.002652  1.001869  0.004254   NaN  0.000060  0.004576    NaN  0.001789  0.005140    NaN    NaN    NaN    NaN    NaN  0.002704  0.006184  0.001899    NaN  0.008183  0.005560  0.002983   0.0   2.0    1.0    0.0    6.0    0.0    1.0   CO    O   NaN   3.0       0  \n",
       "4  0.007841  0.003264   NaN  0.000467  0.009311   NaN  0.005307  0.003116   NaN     1  0.005995  0.009058  0.007263  0.002803  0.006336  0.000266  1.007604  0.006980  0.005827  0.006047  0.006960  0.002473  0.001454  0.009854  0.004971  0.002976  0.001382  0.297843  0.132099  0.081818  0.971905  0.002345  0.589246  1.004867  0.963496  0.809463    NaN  1.006895  0.002269  0.007787   NaN  1.006920    NaN  0.001815    NaN    NaN   NaN  1.008149  0.116816       NaN  0.002960  0.448481  0.442338  0.436173  0.565815  0.435161  0.003628  0.181963  0.000091  0.007207  1.006172  1.008584  0.001068   NaN  1.006119  0.008897    NaN  0.005045  0.003706    NaN    NaN    NaN    NaN    NaN  0.002974  0.004162  0.005764    NaN  0.008154  0.006944  0.000905   0.0   1.0    1.0    0.0    4.0    0.0    1.0   CO    O   1.0   6.0       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cfdafac-2c34-4786-b0a7-8013321d4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.fillna(0, inplace=True)\n",
    "raw_data['const'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2841ef36-3691-4752-9064-8c519345516e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>D_44</th>\n",
       "      <th>B_4</th>\n",
       "      <th>D_45</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_46</th>\n",
       "      <th>D_47</th>\n",
       "      <th>D_48</th>\n",
       "      <th>D_49</th>\n",
       "      <th>B_6</th>\n",
       "      <th>B_7</th>\n",
       "      <th>B_8</th>\n",
       "      <th>D_50</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>D_52</th>\n",
       "      <th>P_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>D_53</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>D_54</th>\n",
       "      <th>R_4</th>\n",
       "      <th>S_7</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>D_55</th>\n",
       "      <th>D_56</th>\n",
       "      <th>B_13</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>S_9</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_59</th>\n",
       "      <th>D_60</th>\n",
       "      <th>D_61</th>\n",
       "      <th>B_15</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_62</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_16</th>\n",
       "      <th>B_17</th>\n",
       "      <th>B_18</th>\n",
       "      <th>B_19</th>\n",
       "      <th>B_20</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_69</th>\n",
       "      <th>B_22</th>\n",
       "      <th>D_70</th>\n",
       "      <th>D_71</th>\n",
       "      <th>D_72</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>D_73</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_74</th>\n",
       "      <th>D_75</th>\n",
       "      <th>D_76</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>D_77</th>\n",
       "      <th>B_25</th>\n",
       "      <th>B_26</th>\n",
       "      <th>D_78</th>\n",
       "      <th>D_79</th>\n",
       "      <th>R_8</th>\n",
       "      <th>R_9</th>\n",
       "      <th>S_16</th>\n",
       "      <th>D_80</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>B_27</th>\n",
       "      <th>D_81</th>\n",
       "      <th>D_82</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>D_83</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>D_84</th>\n",
       "      <th>R_16</th>\n",
       "      <th>B_29</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>D_87</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>D_88</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>B_33</th>\n",
       "      <th>D_89</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_91</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_23</th>\n",
       "      <th>S_24</th>\n",
       "      <th>S_25</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>D_103</th>\n",
       "      <th>D_104</th>\n",
       "      <th>D_105</th>\n",
       "      <th>D_106</th>\n",
       "      <th>D_107</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>R_26</th>\n",
       "      <th>R_27</th>\n",
       "      <th>D_108</th>\n",
       "      <th>D_109</th>\n",
       "      <th>D_110</th>\n",
       "      <th>D_111</th>\n",
       "      <th>B_39</th>\n",
       "      <th>D_112</th>\n",
       "      <th>B_40</th>\n",
       "      <th>S_27</th>\n",
       "      <th>D_113</th>\n",
       "      <th>D_115</th>\n",
       "      <th>D_118</th>\n",
       "      <th>D_119</th>\n",
       "      <th>D_121</th>\n",
       "      <th>D_122</th>\n",
       "      <th>D_123</th>\n",
       "      <th>D_124</th>\n",
       "      <th>D_125</th>\n",
       "      <th>D_127</th>\n",
       "      <th>D_128</th>\n",
       "      <th>D_129</th>\n",
       "      <th>B_41</th>\n",
       "      <th>B_42</th>\n",
       "      <th>D_130</th>\n",
       "      <th>D_131</th>\n",
       "      <th>D_132</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_134</th>\n",
       "      <th>D_135</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>B_30</th>\n",
       "      <th>B_38</th>\n",
       "      <th>D_114</th>\n",
       "      <th>D_116</th>\n",
       "      <th>D_117</th>\n",
       "      <th>D_120</th>\n",
       "      <th>D_126</th>\n",
       "      <th>D_66</th>\n",
       "      <th>D_68</th>\n",
       "      <th>target</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8.294000e+03</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.00000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.000000</td>\n",
       "      <td>8294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.627203</td>\n",
       "      <td>2.015176e-01</td>\n",
       "      <td>0.141932</td>\n",
       "      <td>0.584941</td>\n",
       "      <td>0.114315</td>\n",
       "      <td>0.200622</td>\n",
       "      <td>0.104267</td>\n",
       "      <td>0.155456</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>0.118899</td>\n",
       "      <td>0.136303</td>\n",
       "      <td>0.190916</td>\n",
       "      <td>0.241003</td>\n",
       "      <td>7.814819e-02</td>\n",
       "      <td>0.084833</td>\n",
       "      <td>0.392895</td>\n",
       "      <td>0.399625</td>\n",
       "      <td>0.372252</td>\n",
       "      <td>0.023717</td>\n",
       "      <td>0.138098</td>\n",
       "      <td>0.204513</td>\n",
       "      <td>0.487510</td>\n",
       "      <td>0.081150</td>\n",
       "      <td>0.146025</td>\n",
       "      <td>0.207410</td>\n",
       "      <td>1.205640e-01</td>\n",
       "      <td>0.180478</td>\n",
       "      <td>0.551903</td>\n",
       "      <td>0.223513</td>\n",
       "      <td>0.035659</td>\n",
       "      <td>0.082420</td>\n",
       "      <td>1.286839e-01</td>\n",
       "      <td>2.392453e-01</td>\n",
       "      <td>0.958815</td>\n",
       "      <td>0.057895</td>\n",
       "      <td>0.193174</td>\n",
       "      <td>0.091796</td>\n",
       "      <td>0.313023</td>\n",
       "      <td>0.315654</td>\n",
       "      <td>0.108198</td>\n",
       "      <td>0.100916</td>\n",
       "      <td>8.188413e-02</td>\n",
       "      <td>0.233919</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>0.111608</td>\n",
       "      <td>0.418828</td>\n",
       "      <td>0.361500</td>\n",
       "      <td>0.417988</td>\n",
       "      <td>0.056766</td>\n",
       "      <td>0.392460</td>\n",
       "      <td>0.177337</td>\n",
       "      <td>0.071327</td>\n",
       "      <td>0.379871</td>\n",
       "      <td>0.344690</td>\n",
       "      <td>0.568431</td>\n",
       "      <td>0.170238</td>\n",
       "      <td>0.265857</td>\n",
       "      <td>0.240615</td>\n",
       "      <td>0.095378</td>\n",
       "      <td>0.249551</td>\n",
       "      <td>7.104016e-02</td>\n",
       "      <td>0.211107</td>\n",
       "      <td>0.117460</td>\n",
       "      <td>0.122620</td>\n",
       "      <td>0.074039</td>\n",
       "      <td>0.052859</td>\n",
       "      <td>0.380806</td>\n",
       "      <td>0.190375</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.134144</td>\n",
       "      <td>0.166958</td>\n",
       "      <td>0.187511</td>\n",
       "      <td>0.016615</td>\n",
       "      <td>0.055793</td>\n",
       "      <td>0.142087</td>\n",
       "      <td>0.175479</td>\n",
       "      <td>0.116307</td>\n",
       "      <td>0.130409</td>\n",
       "      <td>0.095422</td>\n",
       "      <td>0.080310</td>\n",
       "      <td>8.611359e-02</td>\n",
       "      <td>0.019891</td>\n",
       "      <td>6.702960e-02</td>\n",
       "      <td>0.112266</td>\n",
       "      <td>9.613564e-02</td>\n",
       "      <td>0.045199</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.095178</td>\n",
       "      <td>0.119664</td>\n",
       "      <td>4.108649e-02</td>\n",
       "      <td>0.971782</td>\n",
       "      <td>0.170588</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.040991</td>\n",
       "      <td>4.042354e-01</td>\n",
       "      <td>3.060250e-02</td>\n",
       "      <td>0.087262</td>\n",
       "      <td>0.059230</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.007413</td>\n",
       "      <td>3.697192e-02</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.994816</td>\n",
       "      <td>4.988447e-03</td>\n",
       "      <td>0.027996</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.018146</td>\n",
       "      <td>6.643627e-02</td>\n",
       "      <td>2.354743e-02</td>\n",
       "      <td>0.571869</td>\n",
       "      <td>0.008073</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>4.998347e-03</td>\n",
       "      <td>0.060666</td>\n",
       "      <td>8.586191e-02</td>\n",
       "      <td>1.308320e-02</td>\n",
       "      <td>2.332660e-02</td>\n",
       "      <td>0.030922</td>\n",
       "      <td>0.010094</td>\n",
       "      <td>0.033844</td>\n",
       "      <td>0.780971</td>\n",
       "      <td>0.200349</td>\n",
       "      <td>0.736633</td>\n",
       "      <td>0.913514</td>\n",
       "      <td>0.069649</td>\n",
       "      <td>0.194514</td>\n",
       "      <td>0.477190</td>\n",
       "      <td>0.460378</td>\n",
       "      <td>0.206914</td>\n",
       "      <td>0.028321</td>\n",
       "      <td>0.212351</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>0.141097</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>0.837822</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.009031</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.797215</td>\n",
       "      <td>0.205622</td>\n",
       "      <td>0.247188</td>\n",
       "      <td>0.152091</td>\n",
       "      <td>0.271171</td>\n",
       "      <td>0.279264</td>\n",
       "      <td>0.275960</td>\n",
       "      <td>0.526156</td>\n",
       "      <td>0.388970</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>0.299644</td>\n",
       "      <td>0.079094</td>\n",
       "      <td>1.087296e-01</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>0.436156</td>\n",
       "      <td>0.039741</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.224550</td>\n",
       "      <td>0.120561</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>5.180051e-02</td>\n",
       "      <td>5.595814e-03</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.016029</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.013161</td>\n",
       "      <td>0.180931</td>\n",
       "      <td>0.026323</td>\n",
       "      <td>0.166703</td>\n",
       "      <td>0.075615</td>\n",
       "      <td>0.180775</td>\n",
       "      <td>5.501019e-02</td>\n",
       "      <td>0.062874</td>\n",
       "      <td>0.176393</td>\n",
       "      <td>2.838437</td>\n",
       "      <td>0.614541</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>2.33687</td>\n",
       "      <td>0.193272</td>\n",
       "      <td>0.773210</td>\n",
       "      <td>0.116108</td>\n",
       "      <td>4.937545</td>\n",
       "      <td>0.265011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.274376</td>\n",
       "      <td>4.052819e-01</td>\n",
       "      <td>0.235986</td>\n",
       "      <td>0.414609</td>\n",
       "      <td>0.293369</td>\n",
       "      <td>0.203259</td>\n",
       "      <td>0.314986</td>\n",
       "      <td>0.254039</td>\n",
       "      <td>0.135277</td>\n",
       "      <td>0.209093</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.240393</td>\n",
       "      <td>0.241220</td>\n",
       "      <td>2.740436e-01</td>\n",
       "      <td>0.271033</td>\n",
       "      <td>0.238683</td>\n",
       "      <td>0.232918</td>\n",
       "      <td>0.347198</td>\n",
       "      <td>0.089741</td>\n",
       "      <td>0.380433</td>\n",
       "      <td>0.245933</td>\n",
       "      <td>0.499699</td>\n",
       "      <td>0.316928</td>\n",
       "      <td>0.243069</td>\n",
       "      <td>0.288350</td>\n",
       "      <td>2.214816e-01</td>\n",
       "      <td>0.178262</td>\n",
       "      <td>0.222652</td>\n",
       "      <td>3.446576</td>\n",
       "      <td>0.164335</td>\n",
       "      <td>0.280862</td>\n",
       "      <td>2.329115e-01</td>\n",
       "      <td>4.234771e-01</td>\n",
       "      <td>0.209929</td>\n",
       "      <td>0.223652</td>\n",
       "      <td>0.208288</td>\n",
       "      <td>0.369408</td>\n",
       "      <td>0.302777</td>\n",
       "      <td>0.302427</td>\n",
       "      <td>0.192067</td>\n",
       "      <td>0.394756</td>\n",
       "      <td>4.631215e-01</td>\n",
       "      <td>0.272419</td>\n",
       "      <td>0.143212</td>\n",
       "      <td>0.279292</td>\n",
       "      <td>0.207374</td>\n",
       "      <td>0.362833</td>\n",
       "      <td>0.357511</td>\n",
       "      <td>0.287499</td>\n",
       "      <td>0.194557</td>\n",
       "      <td>0.225378</td>\n",
       "      <td>0.555816</td>\n",
       "      <td>0.413135</td>\n",
       "      <td>0.441323</td>\n",
       "      <td>0.374471</td>\n",
       "      <td>0.304993</td>\n",
       "      <td>0.387276</td>\n",
       "      <td>0.280043</td>\n",
       "      <td>0.730544</td>\n",
       "      <td>0.304685</td>\n",
       "      <td>8.806755e-01</td>\n",
       "      <td>4.331414</td>\n",
       "      <td>0.232961</td>\n",
       "      <td>0.246931</td>\n",
       "      <td>0.391213</td>\n",
       "      <td>0.261662</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.245288</td>\n",
       "      <td>0.055446</td>\n",
       "      <td>0.327905</td>\n",
       "      <td>0.233825</td>\n",
       "      <td>0.239449</td>\n",
       "      <td>0.118172</td>\n",
       "      <td>0.412889</td>\n",
       "      <td>1.633575</td>\n",
       "      <td>0.215978</td>\n",
       "      <td>0.226791</td>\n",
       "      <td>2.281112</td>\n",
       "      <td>0.336771</td>\n",
       "      <td>0.233162</td>\n",
       "      <td>5.328070e-01</td>\n",
       "      <td>0.082634</td>\n",
       "      <td>9.590673e-01</td>\n",
       "      <td>0.221002</td>\n",
       "      <td>3.805759e-01</td>\n",
       "      <td>0.159846</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.461250</td>\n",
       "      <td>0.222841</td>\n",
       "      <td>2.505810e-01</td>\n",
       "      <td>0.175161</td>\n",
       "      <td>0.237282</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.275242</td>\n",
       "      <td>1.124985e+01</td>\n",
       "      <td>1.578732e-01</td>\n",
       "      <td>0.420629</td>\n",
       "      <td>0.235998</td>\n",
       "      <td>0.096377</td>\n",
       "      <td>0.049106</td>\n",
       "      <td>1.758754e-01</td>\n",
       "      <td>0.043882</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.071821</td>\n",
       "      <td>2.915752e-03</td>\n",
       "      <td>0.150036</td>\n",
       "      <td>0.166633</td>\n",
       "      <td>0.113895</td>\n",
       "      <td>5.315022e-01</td>\n",
       "      <td>1.350022e-01</td>\n",
       "      <td>0.495502</td>\n",
       "      <td>0.027476</td>\n",
       "      <td>0.064825</td>\n",
       "      <td>2.876306e-03</td>\n",
       "      <td>0.187285</td>\n",
       "      <td>2.864596e-01</td>\n",
       "      <td>8.956804e-02</td>\n",
       "      <td>1.342192e-01</td>\n",
       "      <td>0.158943</td>\n",
       "      <td>0.071093</td>\n",
       "      <td>0.167290</td>\n",
       "      <td>0.631851</td>\n",
       "      <td>0.337345</td>\n",
       "      <td>0.731229</td>\n",
       "      <td>0.241079</td>\n",
       "      <td>0.572308</td>\n",
       "      <td>0.277629</td>\n",
       "      <td>0.499344</td>\n",
       "      <td>0.481633</td>\n",
       "      <td>0.274824</td>\n",
       "      <td>0.149521</td>\n",
       "      <td>0.261599</td>\n",
       "      <td>0.028272</td>\n",
       "      <td>0.236523</td>\n",
       "      <td>0.096850</td>\n",
       "      <td>0.371763</td>\n",
       "      <td>0.066951</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>0.081831</td>\n",
       "      <td>0.093055</td>\n",
       "      <td>0.038950</td>\n",
       "      <td>0.405068</td>\n",
       "      <td>0.755636</td>\n",
       "      <td>0.372152</td>\n",
       "      <td>0.219394</td>\n",
       "      <td>0.256990</td>\n",
       "      <td>0.255203</td>\n",
       "      <td>0.255586</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.236693</td>\n",
       "      <td>0.200093</td>\n",
       "      <td>0.225757</td>\n",
       "      <td>0.278587</td>\n",
       "      <td>3.048875e-01</td>\n",
       "      <td>0.494855</td>\n",
       "      <td>0.495289</td>\n",
       "      <td>0.270725</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>0.414038</td>\n",
       "      <td>0.317074</td>\n",
       "      <td>0.124003</td>\n",
       "      <td>1.818283e-01</td>\n",
       "      <td>2.471121e-02</td>\n",
       "      <td>0.124152</td>\n",
       "      <td>0.029169</td>\n",
       "      <td>0.074898</td>\n",
       "      <td>0.033095</td>\n",
       "      <td>0.082690</td>\n",
       "      <td>0.380776</td>\n",
       "      <td>0.144557</td>\n",
       "      <td>0.350875</td>\n",
       "      <td>0.190649</td>\n",
       "      <td>0.380626</td>\n",
       "      <td>1.880133e-01</td>\n",
       "      <td>0.199252</td>\n",
       "      <td>0.407475</td>\n",
       "      <td>1.671990</td>\n",
       "      <td>0.486733</td>\n",
       "      <td>0.050258</td>\n",
       "      <td>2.30599</td>\n",
       "      <td>0.394888</td>\n",
       "      <td>0.418781</td>\n",
       "      <td>0.320374</td>\n",
       "      <td>1.438378</td>\n",
       "      <td>0.441366</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.302248</td>\n",
       "      <td>8.701630e-07</td>\n",
       "      <td>-0.041103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.222994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.191489e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-1.468013</td>\n",
       "      <td>-0.026451</td>\n",
       "      <td>-0.009262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002596</td>\n",
       "      <td>-0.009891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.327965</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.504980e-07</td>\n",
       "      <td>-0.004973</td>\n",
       "      <td>-0.934615</td>\n",
       "      <td>-0.002785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.028374e-07</td>\n",
       "      <td>4.453817e-07</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.014348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.555585e-07</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016479</td>\n",
       "      <td>-0.080618</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>-0.050945</td>\n",
       "      <td>-0.197848</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.383541</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.781697e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.299473</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.037532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.544758e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.464621e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.190176e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.190073e-07</td>\n",
       "      <td>-0.090166</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.132343e-07</td>\n",
       "      <td>2.955906e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>9.946228e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.079376e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.472595e-07</td>\n",
       "      <td>5.820840e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.512382e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.849652e-07</td>\n",
       "      <td>8.446085e-07</td>\n",
       "      <td>4.298325e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-50.427000</td>\n",
       "      <td>-4.486724</td>\n",
       "      <td>-56.541542</td>\n",
       "      <td>-2.453393</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.118901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.045246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.232229e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.161485e-07</td>\n",
       "      <td>1.381707e-07</td>\n",
       "      <td>-0.004961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.773110e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.443231</td>\n",
       "      <td>4.683250e-03</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.068375</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.103817</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.029786</td>\n",
       "      <td>0.053898</td>\n",
       "      <td>7.201763e-03</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.352477</td>\n",
       "      <td>0.228295</td>\n",
       "      <td>0.052784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018153</td>\n",
       "      <td>0.029276</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>4.457010e-03</td>\n",
       "      <td>0.072390</td>\n",
       "      <td>0.498244</td>\n",
       "      <td>0.026161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>6.717485e-03</td>\n",
       "      <td>3.406132e-03</td>\n",
       "      <td>1.002150</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.076458</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.055155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>2.603587e-03</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.256781</td>\n",
       "      <td>0.032957</td>\n",
       "      <td>0.065105</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.283728</td>\n",
       "      <td>0.023277</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198396</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.004276</td>\n",
       "      <td>0.186966</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.004701</td>\n",
       "      <td>2.702342e-03</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.208190</td>\n",
       "      <td>0.018542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.006093</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>2.567565e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.435009e-03</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>2.675182e-03</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.739519e-03</td>\n",
       "      <td>1.002259</td>\n",
       "      <td>0.030785</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>2.504877e-03</td>\n",
       "      <td>2.575960e-03</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>2.593719e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.472824e-03</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>2.472925e-03</td>\n",
       "      <td>2.542278e-03</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>2.504714e-03</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>2.678924e-03</td>\n",
       "      <td>2.556897e-03</td>\n",
       "      <td>2.605801e-03</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.794423</td>\n",
       "      <td>0.133534</td>\n",
       "      <td>0.786757</td>\n",
       "      <td>0.970594</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000535</td>\n",
       "      <td>0.019419</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.055611</td>\n",
       "      <td>0.059018</td>\n",
       "      <td>0.055501</td>\n",
       "      <td>0.348429</td>\n",
       "      <td>0.150732</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.139769</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>2.811572e-03</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.748788e-03</td>\n",
       "      <td>2.467873e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>2.692259e-03</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.678131</td>\n",
       "      <td>9.489405e-03</td>\n",
       "      <td>0.034268</td>\n",
       "      <td>0.813215</td>\n",
       "      <td>0.006144</td>\n",
       "      <td>0.159174</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.011355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049964</td>\n",
       "      <td>0.007948</td>\n",
       "      <td>0.094079</td>\n",
       "      <td>0.145093</td>\n",
       "      <td>1.511462e-02</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.446887</td>\n",
       "      <td>0.370311</td>\n",
       "      <td>0.245660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074407</td>\n",
       "      <td>0.084897</td>\n",
       "      <td>0.009642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.027474</td>\n",
       "      <td>9.143804e-03</td>\n",
       "      <td>0.143788</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>0.095898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>2.290211e-02</td>\n",
       "      <td>6.735835e-03</td>\n",
       "      <td>1.004731</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.114446</td>\n",
       "      <td>0.018008</td>\n",
       "      <td>0.318209</td>\n",
       "      <td>0.195128</td>\n",
       "      <td>0.034308</td>\n",
       "      <td>0.028382</td>\n",
       "      <td>5.310979e-03</td>\n",
       "      <td>0.118407</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.031105</td>\n",
       "      <td>0.484990</td>\n",
       "      <td>0.218785</td>\n",
       "      <td>0.328782</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.325153</td>\n",
       "      <td>0.078018</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.169080</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.591727</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>0.190748</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>5.244141e-03</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.403814</td>\n",
       "      <td>0.070164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005749</td>\n",
       "      <td>0.076764</td>\n",
       "      <td>0.076018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.097457</td>\n",
       "      <td>0.022701</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>5.165134e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.010261e-03</td>\n",
       "      <td>0.007201</td>\n",
       "      <td>5.369505e-03</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.346069e-03</td>\n",
       "      <td>1.004845</td>\n",
       "      <td>0.085721</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>5.032804e-03</td>\n",
       "      <td>5.196005e-03</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>5.232055e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.975763e-03</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>5.056035e-03</td>\n",
       "      <td>5.051535e-03</td>\n",
       "      <td>1.001152</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>5.011551e-03</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>5.365391e-03</td>\n",
       "      <td>5.102612e-03</td>\n",
       "      <td>5.048285e-03</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.942930</td>\n",
       "      <td>0.136451</td>\n",
       "      <td>0.949295</td>\n",
       "      <td>0.973564</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.009454</td>\n",
       "      <td>0.009476</td>\n",
       "      <td>0.039755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.033844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.004006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003778</td>\n",
       "      <td>0.070463</td>\n",
       "      <td>0.008935</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>0.182212</td>\n",
       "      <td>0.208164</td>\n",
       "      <td>0.203436</td>\n",
       "      <td>0.589882</td>\n",
       "      <td>0.294928</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.272923</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>5.587587e-03</td>\n",
       "      <td>1.000126</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.468883e-03</td>\n",
       "      <td>5.041905e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>5.441762e-03</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.859477</td>\n",
       "      <td>2.598406e-01</td>\n",
       "      <td>0.157853</td>\n",
       "      <td>1.001955</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>0.235840</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>0.217881</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.138138</td>\n",
       "      <td>0.133929</td>\n",
       "      <td>0.270217</td>\n",
       "      <td>0.360271</td>\n",
       "      <td>5.062409e-02</td>\n",
       "      <td>0.008105</td>\n",
       "      <td>0.498968</td>\n",
       "      <td>0.548097</td>\n",
       "      <td>0.697312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189571</td>\n",
       "      <td>0.307462</td>\n",
       "      <td>1.004661</td>\n",
       "      <td>0.100377</td>\n",
       "      <td>0.336111</td>\n",
       "      <td>0.425651</td>\n",
       "      <td>1.098933e-01</td>\n",
       "      <td>0.232164</td>\n",
       "      <td>0.672071</td>\n",
       "      <td>0.294985</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.066691</td>\n",
       "      <td>1.302218e-01</td>\n",
       "      <td>9.771226e-03</td>\n",
       "      <td>1.007353</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>0.256885</td>\n",
       "      <td>0.067981</td>\n",
       "      <td>0.491550</td>\n",
       "      <td>0.547588</td>\n",
       "      <td>0.156409</td>\n",
       "      <td>0.089163</td>\n",
       "      <td>7.843511e-03</td>\n",
       "      <td>0.409165</td>\n",
       "      <td>0.018813</td>\n",
       "      <td>0.112380</td>\n",
       "      <td>0.527927</td>\n",
       "      <td>0.650975</td>\n",
       "      <td>0.796511</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.484944</td>\n",
       "      <td>0.266349</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.841343</td>\n",
       "      <td>0.894745</td>\n",
       "      <td>1.002972</td>\n",
       "      <td>0.167189</td>\n",
       "      <td>0.477552</td>\n",
       "      <td>0.201212</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.427825</td>\n",
       "      <td>7.719386e-03</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.251907</td>\n",
       "      <td>0.031713</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>0.505093</td>\n",
       "      <td>0.282334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>0.222576</td>\n",
       "      <td>0.273151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>0.278789</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.008549</td>\n",
       "      <td>7.775796e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.610997e-03</td>\n",
       "      <td>0.202605</td>\n",
       "      <td>7.997242e-03</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>8.069134e-03</td>\n",
       "      <td>1.007431</td>\n",
       "      <td>0.217470</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>7.704036e-03</td>\n",
       "      <td>7.748600e-03</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.008088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007468</td>\n",
       "      <td>7.758543e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.007456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.462496e-03</td>\n",
       "      <td>0.007647</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>7.690752e-03</td>\n",
       "      <td>7.569707e-03</td>\n",
       "      <td>1.005645</td>\n",
       "      <td>0.007593</td>\n",
       "      <td>0.007455</td>\n",
       "      <td>7.522645e-03</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>8.098484e-03</td>\n",
       "      <td>7.505132e-03</td>\n",
       "      <td>7.586892e-03</td>\n",
       "      <td>0.007685</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.965458</td>\n",
       "      <td>0.139293</td>\n",
       "      <td>0.972004</td>\n",
       "      <td>0.976493</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>0.330647</td>\n",
       "      <td>1.004769</td>\n",
       "      <td>0.964963</td>\n",
       "      <td>0.370034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339733</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.154426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.007054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.006941</td>\n",
       "      <td>0.274219</td>\n",
       "      <td>0.460285</td>\n",
       "      <td>0.207468</td>\n",
       "      <td>0.430913</td>\n",
       "      <td>0.437445</td>\n",
       "      <td>0.432894</td>\n",
       "      <td>0.721157</td>\n",
       "      <td>0.575096</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>0.415673</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>8.464614e-03</td>\n",
       "      <td>1.004589</td>\n",
       "      <td>1.004205</td>\n",
       "      <td>0.007750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009611</td>\n",
       "      <td>0.008515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.265552e-03</td>\n",
       "      <td>7.484257e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>8.269200e-03</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.009893</td>\n",
       "      <td>3.382558e+00</td>\n",
       "      <td>1.324053</td>\n",
       "      <td>1.009994</td>\n",
       "      <td>2.507711</td>\n",
       "      <td>2.581047</td>\n",
       "      <td>4.895638</td>\n",
       "      <td>1.392542</td>\n",
       "      <td>2.683582</td>\n",
       "      <td>5.207347</td>\n",
       "      <td>2.631604</td>\n",
       "      <td>2.302243</td>\n",
       "      <td>1.471538</td>\n",
       "      <td>7.936593e+00</td>\n",
       "      <td>1.009943</td>\n",
       "      <td>3.253279</td>\n",
       "      <td>1.299262</td>\n",
       "      <td>1.670968</td>\n",
       "      <td>1.409152</td>\n",
       "      <td>19.359715</td>\n",
       "      <td>1.252429</td>\n",
       "      <td>1.010031</td>\n",
       "      <td>19.979746</td>\n",
       "      <td>2.007093</td>\n",
       "      <td>3.896068</td>\n",
       "      <td>5.506437e+00</td>\n",
       "      <td>1.009977</td>\n",
       "      <td>1.545103</td>\n",
       "      <td>305.996550</td>\n",
       "      <td>3.946607</td>\n",
       "      <td>13.746441</td>\n",
       "      <td>1.431039e+00</td>\n",
       "      <td>1.010000e+00</td>\n",
       "      <td>1.009999</td>\n",
       "      <td>1.009983</td>\n",
       "      <td>2.527142</td>\n",
       "      <td>13.430799</td>\n",
       "      <td>1.228537</td>\n",
       "      <td>1.396794</td>\n",
       "      <td>5.647300</td>\n",
       "      <td>18.048244</td>\n",
       "      <td>1.000677e+01</td>\n",
       "      <td>1.261522</td>\n",
       "      <td>2.829905</td>\n",
       "      <td>7.725728</td>\n",
       "      <td>1.340264</td>\n",
       "      <td>1.009985</td>\n",
       "      <td>3.124886</td>\n",
       "      <td>9.044584</td>\n",
       "      <td>1.969182</td>\n",
       "      <td>4.346862</td>\n",
       "      <td>34.242493</td>\n",
       "      <td>1.009988</td>\n",
       "      <td>1.009987</td>\n",
       "      <td>1.009998</td>\n",
       "      <td>1.009996</td>\n",
       "      <td>1.009993</td>\n",
       "      <td>16.746990</td>\n",
       "      <td>14.448057</td>\n",
       "      <td>1.009999</td>\n",
       "      <td>3.748253e+01</td>\n",
       "      <td>251.640400</td>\n",
       "      <td>2.000263</td>\n",
       "      <td>3.505832</td>\n",
       "      <td>26.583454</td>\n",
       "      <td>3.009846</td>\n",
       "      <td>2.706485</td>\n",
       "      <td>1.378147</td>\n",
       "      <td>3.846035</td>\n",
       "      <td>1.152324</td>\n",
       "      <td>2.429710</td>\n",
       "      <td>2.400041</td>\n",
       "      <td>6.261484</td>\n",
       "      <td>14.398432</td>\n",
       "      <td>63.617226</td>\n",
       "      <td>4.003156</td>\n",
       "      <td>3.165502</td>\n",
       "      <td>163.303740</td>\n",
       "      <td>5.009027</td>\n",
       "      <td>3.009253</td>\n",
       "      <td>1.400612e+01</td>\n",
       "      <td>1.508624</td>\n",
       "      <td>6.643619e+01</td>\n",
       "      <td>3.209090</td>\n",
       "      <td>7.006044e+00</td>\n",
       "      <td>2.004113</td>\n",
       "      <td>0.096994</td>\n",
       "      <td>8.009847</td>\n",
       "      <td>1.508871</td>\n",
       "      <td>4.049058e+00</td>\n",
       "      <td>1.009999</td>\n",
       "      <td>3.861047</td>\n",
       "      <td>0.297147</td>\n",
       "      <td>6.007940</td>\n",
       "      <td>9.249002e+02</td>\n",
       "      <td>1.010000e+00</td>\n",
       "      <td>9.503566</td>\n",
       "      <td>5.507145</td>\n",
       "      <td>4.415590</td>\n",
       "      <td>1.009495</td>\n",
       "      <td>1.009914e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380176</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.576102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.284463e-02</td>\n",
       "      <td>1.009906</td>\n",
       "      <td>1.009996</td>\n",
       "      <td>1.009960</td>\n",
       "      <td>2.100100e+01</td>\n",
       "      <td>1.009976e+00</td>\n",
       "      <td>1.009990</td>\n",
       "      <td>1.003476</td>\n",
       "      <td>1.009754</td>\n",
       "      <td>9.998021e-03</td>\n",
       "      <td>2.004067</td>\n",
       "      <td>2.009786e+00</td>\n",
       "      <td>1.009963e+00</td>\n",
       "      <td>1.009928e+00</td>\n",
       "      <td>1.009880</td>\n",
       "      <td>1.009859</td>\n",
       "      <td>1.009966</td>\n",
       "      <td>1.031959</td>\n",
       "      <td>11.013209</td>\n",
       "      <td>1.046993</td>\n",
       "      <td>1.565287</td>\n",
       "      <td>36.969303</td>\n",
       "      <td>1.089628</td>\n",
       "      <td>1.009999</td>\n",
       "      <td>1.103441</td>\n",
       "      <td>2.490803</td>\n",
       "      <td>8.048535</td>\n",
       "      <td>2.674745</td>\n",
       "      <td>0.521870</td>\n",
       "      <td>1.326853</td>\n",
       "      <td>4.329881</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>4.006406</td>\n",
       "      <td>1.009924</td>\n",
       "      <td>1.009488</td>\n",
       "      <td>1.009969</td>\n",
       "      <td>1.008125</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>36.800056</td>\n",
       "      <td>4.625815</td>\n",
       "      <td>1.607378</td>\n",
       "      <td>1.454306</td>\n",
       "      <td>1.440474</td>\n",
       "      <td>1.442280</td>\n",
       "      <td>1.295574</td>\n",
       "      <td>1.577900</td>\n",
       "      <td>2.004210</td>\n",
       "      <td>1.643043</td>\n",
       "      <td>2.009533</td>\n",
       "      <td>1.009986e+00</td>\n",
       "      <td>1.010775</td>\n",
       "      <td>1.009999</td>\n",
       "      <td>12.006965</td>\n",
       "      <td>2.884557</td>\n",
       "      <td>1.011000</td>\n",
       "      <td>1.319955</td>\n",
       "      <td>4.039000</td>\n",
       "      <td>1.509167e+00</td>\n",
       "      <td>1.007785e+00</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>1.007165</td>\n",
       "      <td>1.505735</td>\n",
       "      <td>1.007997</td>\n",
       "      <td>1.502486</td>\n",
       "      <td>1.009998</td>\n",
       "      <td>1.009944</td>\n",
       "      <td>1.174753</td>\n",
       "      <td>1.747922</td>\n",
       "      <td>1.009982</td>\n",
       "      <td>1.341404e+00</td>\n",
       "      <td>4.187805</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P_2          D_39          B_1          B_2          R_1          S_3         D_41          B_3         D_42         D_43         D_44          B_4         D_45           B_5          R_2         D_46         D_47         D_48         D_49          B_6          B_7          B_8         D_50         D_51          B_9           R_3         D_52          P_3         B_10         D_53          S_5          B_11           S_6         D_54          R_4          S_7         B_12          S_8         D_55         D_56         B_13           R_5         D_58          S_9         B_14         D_59         D_60         D_61         B_15         S_11         D_62         D_65         B_16         B_17         B_18         B_19         B_20         S_12          R_6         S_13          B_21         D_69         B_22         D_70         D_71         D_72         S_15         B_23         D_73          P_4         D_74         D_75         D_76         B_24          R_7  \\\n",
       "count  8294.000000  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000   \n",
       "mean      0.627203  2.015176e-01     0.141932     0.584941     0.114315     0.200622     0.104267     0.155456     0.041790     0.118899     0.136303     0.190916     0.241003  7.814819e-02     0.084833     0.392895     0.399625     0.372252     0.023717     0.138098     0.204513     0.487510     0.081150     0.146025     0.207410  1.205640e-01     0.180478     0.551903     0.223513     0.035659     0.082420  1.286839e-01  2.392453e-01     0.958815     0.057895     0.193174     0.091796     0.313023     0.315654     0.108198     0.100916  8.188413e-02     0.233919     0.036105     0.111608     0.418828     0.361500     0.417988     0.056766     0.392460     0.177337     0.071327     0.379871     0.344690     0.568431     0.170238     0.265857     0.240615     0.095378     0.249551  7.104016e-02     0.211107     0.117460     0.122620     0.074039     0.052859     0.380806     0.190375     0.003842     0.134144     0.166958     0.187511     0.016615     0.055793     0.142087   \n",
       "std       0.274376  4.052819e-01     0.235986     0.414609     0.293369     0.203259     0.314986     0.254039     0.135277     0.209093     0.245000     0.240393     0.241220  2.740436e-01     0.271033     0.238683     0.232918     0.347198     0.089741     0.380433     0.245933     0.499699     0.316928     0.243069     0.288350  2.214816e-01     0.178262     0.222652     3.446576     0.164335     0.280862  2.329115e-01  4.234771e-01     0.209929     0.223652     0.208288     0.369408     0.302777     0.302427     0.192067     0.394756  4.631215e-01     0.272419     0.143212     0.279292     0.207374     0.362833     0.357511     0.287499     0.194557     0.225378     0.555816     0.413135     0.441323     0.374471     0.304993     0.387276     0.280043     0.730544     0.304685  8.806755e-01     4.331414     0.232961     0.246931     0.391213     0.261662     0.199103     0.245288     0.055446     0.327905     0.233825     0.239449     0.118172     0.412889     1.633575   \n",
       "min      -0.302248  8.701630e-07    -0.041103     0.000000     0.000001    -0.222994     0.000000     0.000000    -0.000219     0.000000     0.000000     0.000013     0.000000  2.191489e-07     0.000002    -1.468013    -0.026451    -0.009262     0.000000    -0.002596    -0.009891     0.000000    -0.327965     0.000005     0.000006  2.504980e-07    -0.004973    -0.934615    -0.002785     0.000000     0.000003  2.028374e-07  4.453817e-07    -0.001984     0.000001    -0.171527     0.000067     0.000002     0.000000    -0.014348     0.000000  1.555585e-07     0.000008     0.000000    -0.016479    -0.080618     0.000003    -0.009143    -0.050945    -0.197848    -0.000823     0.000001     0.000000     0.000000     0.000004     0.000000     0.000000    -0.383541     0.000002     0.000005  1.781697e-07     0.000000     0.000000     0.000000     0.000038     0.000000    -0.299473     0.000018     0.000000     0.000003     0.000000     0.000006     0.000000     0.000003     0.000002   \n",
       "25%       0.443231  4.683250e-03     0.009002     0.068375     0.003030     0.103817     0.002961     0.005524     0.000000     0.006331     0.003655     0.029786     0.053898  7.201763e-03     0.002775     0.352477     0.228295     0.052784     0.000000     0.018153     0.029276     0.004769     0.000000     0.003763     0.005617  4.457010e-03     0.072390     0.498244     0.026161     0.000000     0.005713  6.717485e-03  3.406132e-03     1.002150     0.002737     0.076458     0.010648     0.007222     0.055155     0.000000     0.009044  2.603587e-03     0.006174     0.000000     0.008453     0.256781     0.032957     0.065105     0.003097     0.283728     0.023277     0.002686     0.006505     0.000000     0.198396     0.003495     0.004276     0.186966     0.002622     0.004701  2.702342e-03     0.002438     0.003128     0.003357     0.008514     0.002704     0.208190     0.018542     0.000000     0.002888     0.006085     0.006979     0.000000     0.002590     0.002648   \n",
       "50%       0.678131  9.489405e-03     0.034268     0.813215     0.006144     0.159174     0.006002     0.011355     0.000000     0.049964     0.007948     0.094079     0.145093  1.511462e-02     0.005479     0.446887     0.370311     0.245660     0.000000     0.074407     0.084897     0.009642     0.000000     0.007385     0.027474  9.143804e-03     0.143788     0.607407     0.095898     0.000000     0.013461  2.290211e-02  6.735835e-03     1.004731     0.005424     0.114446     0.018008     0.318209     0.195128     0.034308     0.028382  5.310979e-03     0.118407     0.007577     0.031105     0.484990     0.218785     0.328782     0.006233     0.325153     0.078018     0.005457     0.169080     0.002920     0.591727     0.007211     0.008557     0.190748     0.005392     0.009417  5.244141e-03     0.005081     0.006275     0.006852     0.012690     0.005261     0.403814     0.070164     0.000000     0.005749     0.076764     0.076018     0.000000     0.005275     0.005239   \n",
       "75%       0.859477  2.598406e-01     0.157853     1.001955     0.008980     0.235840     0.009089     0.217881     0.001132     0.138138     0.133929     0.270217     0.360271  5.062409e-02     0.008105     0.498968     0.548097     0.697312     0.000000     0.189571     0.307462     1.004661     0.100377     0.336111     0.425651  1.098933e-01     0.232164     0.672071     0.294985     0.006100     0.066691  1.302218e-01  9.771226e-03     1.007353     0.007954     0.256885     0.067981     0.491550     0.547588     0.156409     0.089163  7.843511e-03     0.409165     0.018813     0.112380     0.527927     0.650975     0.796511     0.009349     0.484944     0.266349     0.008162     0.841343     0.894745     1.002972     0.167189     0.477552     0.201212     0.008089     0.427825  7.719386e-03     0.007698     0.009481     0.251907     0.031713     0.007963     0.505093     0.282334     0.000000     0.008568     0.222576     0.273151     0.000000     0.007902     0.007868   \n",
       "max       1.009893  3.382558e+00     1.324053     1.009994     2.507711     2.581047     4.895638     1.392542     2.683582     5.207347     2.631604     2.302243     1.471538  7.936593e+00     1.009943     3.253279     1.299262     1.670968     1.409152    19.359715     1.252429     1.010031    19.979746     2.007093     3.896068  5.506437e+00     1.009977     1.545103   305.996550     3.946607    13.746441  1.431039e+00  1.010000e+00     1.009999     1.009983     2.527142    13.430799     1.228537     1.396794     5.647300    18.048244  1.000677e+01     1.261522     2.829905     7.725728     1.340264     1.009985     3.124886     9.044584     1.969182     4.346862    34.242493     1.009988     1.009987     1.009998     1.009996     1.009993    16.746990    14.448057     1.009999  3.748253e+01   251.640400     2.000263     3.505832    26.583454     3.009846     2.706485     1.378147     3.846035     1.152324     2.429710     2.400041     6.261484    14.398432    63.617226   \n",
       "\n",
       "              D_77         B_25         B_26         D_78         D_79           R_8          R_9          S_16         D_80          R_10         R_11         B_27         D_81         D_82          S_17         R_12         B_28         R_13         D_83          R_14          R_15         D_84         R_16         B_29         S_18          D_86         D_87         R_17         R_18         D_88         B_31          S_19         R_19         B_32         S_20          R_20          R_21         B_33         D_89         R_22          R_23         D_91          D_92          D_93          D_94         R_24         R_25         D_96         S_22         S_23         S_24         S_25         S_26        D_102        D_103        D_104        D_105        D_106        D_107         B_36         B_37         R_26         R_27        D_108        D_109        D_110        D_111         B_39        D_112         B_40         S_27        D_113        D_115        D_118        D_119  \\\n",
       "count  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8294.000000  8.294000e+03  8294.000000  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8294.000000  8294.000000  8294.000000  8.294000e+03  8.294000e+03  8294.000000  8294.000000  8294.000000  8.294000e+03  8294.000000  8.294000e+03  8.294000e+03  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000   \n",
       "mean      0.175479     0.116307     0.130409     0.095422     0.080310  8.611359e-02     0.019891  6.702960e-02     0.112266  9.613564e-02     0.045199     0.005026     0.095178     0.119664  4.108649e-02     0.971782     0.170588     0.006454     0.040991  4.042354e-01  3.060250e-02     0.087262     0.059230     0.003727     0.007413  3.697192e-02     0.001929     0.005842     0.004984     0.000972     0.994816  4.988447e-03     0.027996     0.033581     0.018146  6.643627e-02  2.354743e-02     0.571869     0.008073     0.009174  4.998347e-03     0.060666  8.586191e-02  1.308320e-02  2.332660e-02     0.030922     0.010094     0.033844     0.780971     0.200349     0.736633     0.913514     0.069649     0.194514     0.477190     0.460378     0.206914     0.028321     0.212351     0.007427     0.141097     0.010362     0.837822     0.002764     0.005871     0.007692     0.009031     0.002799     0.797215     0.205622     0.247188     0.152091     0.271171     0.279264     0.275960   \n",
       "std       0.215978     0.226791     2.281112     0.336771     0.233162  5.328070e-01     0.082634  9.590673e-01     0.221002  3.805759e-01     0.159846     0.003174     0.461250     0.222841  2.505810e-01     0.175161     0.237282     0.012319     0.275242  1.124985e+01  1.578732e-01     0.420629     0.235998     0.096377     0.049106  1.758754e-01     0.043882     0.010085     0.002883     0.017259     0.071821  2.915752e-03     0.150036     0.166633     0.113895  5.315022e-01  1.350022e-01     0.495502     0.027476     0.064825  2.876306e-03     0.187285  2.864596e-01  8.956804e-02  1.342192e-01     0.158943     0.071093     0.167290     0.631851     0.337345     0.731229     0.241079     0.572308     0.277629     0.499344     0.481633     0.274824     0.149521     0.261599     0.028272     0.236523     0.096850     0.371763     0.066951     0.029155     0.081831     0.093055     0.038950     0.405068     0.755636     0.372152     0.219394     0.256990     0.255203     0.255586   \n",
       "min       0.000000    -0.037532     0.000000     0.000000     0.000000  2.544758e-07     0.000000  3.464621e-07     0.000000  6.190176e-07     0.000001     0.000000     0.000000     0.000000  2.190073e-07    -0.090166     0.000015     0.000001     0.000000  3.132343e-07  2.955906e-07     0.000000     0.000002     0.000000     0.000003  9.946228e-07     0.000000     0.000001     0.000003     0.000000     0.000000  6.079376e-07     0.000004     0.000006     0.000003  2.472595e-07  5.820840e-07     0.000000     0.000000     0.000002  2.512382e-07     0.000000  1.849652e-07  8.446085e-07  4.298325e-07     0.000003     0.000003     0.000001   -50.427000    -4.486724   -56.541542    -2.453393     0.000001     0.000008     0.000000     0.000000    -0.011863     0.000000     0.000000     0.000002    -0.118901     0.000000    -0.008854     0.000000     0.000000     0.000000     0.000000    -0.016880     0.000000     0.000004     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.010768     0.006093     0.002728     0.002375     0.002828  2.567565e-03     0.000000  2.435009e-03     0.003568  2.675182e-03     0.002683     0.002473     0.002637     0.000000  2.739519e-03     1.002259     0.030785     0.002613     0.002427  2.504877e-03  2.575960e-03     0.002629     0.002736     0.000000     0.002519  2.593719e-03     0.000000     0.002556     0.002538     0.000000     1.000000  2.472824e-03     0.002457     0.002609     0.002592  2.472925e-03  2.542278e-03     0.006000     0.002549     0.002496  2.504714e-03     0.002557  2.678924e-03  2.556897e-03  2.605801e-03     0.002574     0.002570     0.002563     0.794423     0.133534     0.786757     0.970594     0.003358     0.004626     0.004527     0.004580     0.000000     0.000000     0.004616     0.002494     0.008956     0.000000     1.000995     0.000000     0.002529     0.000000     0.000000     0.000000     1.000535     0.019419     0.002512     0.004159     0.055611     0.059018     0.055501   \n",
       "50%       0.097457     0.022701     0.005401     0.005257     0.005706  5.165134e-03     0.000000  5.010261e-03     0.007201  5.369505e-03     0.005369     0.004966     0.005344     0.000000  5.346069e-03     1.004845     0.085721     0.005155     0.005105  5.032804e-03  5.196005e-03     0.005362     0.005365     0.000000     0.005017  5.232055e-03     0.000000     0.005094     0.004970     0.000000     1.000000  4.975763e-03     0.005126     0.005159     0.005090  5.056035e-03  5.051535e-03     1.001152     0.005067     0.004936  5.011551e-03     0.005516  5.365391e-03  5.102612e-03  5.048285e-03     0.005158     0.005087     0.005240     0.942930     0.136451     0.949295     0.973564     0.006641     0.009132     0.009454     0.009476     0.039755     0.000000     0.009474     0.005037     0.033844     0.000000     1.004006     0.000000     0.005010     0.000000     0.000000     0.000000     1.003778     0.070463     0.008935     0.008630     0.182212     0.208164     0.203436   \n",
       "75%       0.278789     0.121817     0.008156     0.008216     0.008549  7.775796e-03     0.000000  7.610997e-03     0.202605  7.997242e-03     0.008041     0.007559     0.007990     0.005365  8.069134e-03     1.007431     0.217470     0.007695     0.007678  7.704036e-03  7.748600e-03     0.008050     0.008088     0.000000     0.007468  7.758543e-03     0.000000     0.007631     0.007456     0.000000     1.000000  7.462496e-03     0.007647     0.007729     0.007579  7.690752e-03  7.569707e-03     1.005645     0.007593     0.007455  7.522645e-03     0.008259  8.098484e-03  7.505132e-03  7.586892e-03     0.007685     0.007518     0.007781     0.965458     0.139293     0.972004     0.976493     0.009894     0.330647     1.004769     0.964963     0.370034     0.000000     0.339733     0.007542     0.154426     0.000000     1.007054     0.000000     0.007556     0.000000     0.000000     0.000000     1.006941     0.274219     0.460285     0.207468     0.430913     0.437445     0.432894   \n",
       "max       4.003156     3.165502   163.303740     5.009027     3.009253  1.400612e+01     1.508624  6.643619e+01     3.209090  7.006044e+00     2.004113     0.096994     8.009847     1.508871  4.049058e+00     1.009999     3.861047     0.297147     6.007940  9.249002e+02  1.010000e+00     9.503566     5.507145     4.415590     1.009495  1.009914e+00     1.000000     0.380176     0.010000     0.576102     1.000000  4.284463e-02     1.009906     1.009996     1.009960  2.100100e+01  1.009976e+00     1.009990     1.003476     1.009754  9.998021e-03     2.004067  2.009786e+00  1.009963e+00  1.009928e+00     1.009880     1.009859     1.009966     1.031959    11.013209     1.046993     1.565287    36.969303     1.089628     1.009999     1.103441     2.490803     8.048535     2.674745     0.521870     1.326853     4.329881     1.010000     4.006406     1.009924     1.009488     1.009969     1.008125     1.010000    36.800056     4.625815     1.607378     1.454306     1.440474     1.442280   \n",
       "\n",
       "             D_121        D_122        D_123        D_124        D_125         D_127        D_128        D_129         B_41         B_42        D_130        D_131        D_132         D_133          R_28        D_134        D_135        D_136        D_137        D_138        D_139        D_140        D_141        D_142        D_143         D_144        D_145         B_30         B_38        D_114        D_116       D_117        D_120        D_126         D_66         D_68       target   const  \n",
       "count  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8.294000e+03  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.00000  8294.000000  8294.000000  8294.000000  8294.000000  8294.000000  8294.0  \n",
       "mean      0.526156     0.388970     0.046121     0.299644     0.079094  1.087296e-01     0.573000     0.436156     0.039741     0.001854     0.224550     0.120561     0.030535  5.180051e-02  5.595814e-03     0.025981     0.001224     0.016029     0.001475     0.013161     0.180931     0.026323     0.166703     0.075615     0.180775  5.501019e-02     0.062874     0.176393     2.838437     0.614541     0.002532     2.33687     0.193272     0.773210     0.116108     4.937545     0.265011     1.0  \n",
       "std       0.241667     0.236693     0.200093     0.225757     0.278587  3.048875e-01     0.494855     0.495289     0.270725     0.041443     0.414038     0.317074     0.124003  1.818283e-01  2.471121e-02     0.124152     0.029169     0.074898     0.033095     0.082690     0.380776     0.144557     0.350875     0.190649     0.380626  1.880133e-01     0.199252     0.407475     1.671990     0.486733     0.050258     2.30599     0.394888     0.418781     0.320374     1.438378     0.441366     0.0  \n",
       "min      -0.031702     0.000000     0.000000    -0.045246     0.000000  5.232229e-07     0.000000     0.000000     0.000006     0.000000     0.000000     0.000000     0.000000  7.161485e-07  1.381707e-07    -0.004961     0.000000     0.000000     0.000000     0.000000     0.000000     0.000001     0.000000    -0.008804     0.000000  7.773110e-07     0.000000     0.000000     0.000000     0.000000     0.000000    -1.00000     0.000000     0.000000     0.000000     0.000000     0.000000     1.0  \n",
       "25%       0.348429     0.150732     0.002422     0.139769     0.002564  2.811572e-03     0.005725     0.004472     0.002608     0.000000     0.003081     0.002706     0.000000  2.748788e-03  2.467873e-03     0.000000     0.000000     0.000000     0.000000     0.000000     0.003114     0.002524     0.002946     0.000000     0.003060  2.692259e-03     0.002889     0.000000     2.000000     0.000000     0.000000    -1.00000     0.000000     1.000000     0.000000     4.000000     0.000000     1.0  \n",
       "50%       0.589882     0.294928     0.005046     0.272923     0.005331  5.587587e-03     1.000126     0.008734     0.005164     0.000000     0.006445     0.005618     0.000000  5.468883e-03  5.041905e-03     0.000000     0.000000     0.000000     0.000000     0.000000     0.006100     0.005076     0.005975     0.000000     0.006097  5.441762e-03     0.005962     0.000000     2.000000     1.000000     0.000000     3.00000     0.000000     1.000000     0.000000     6.000000     0.000000     1.0  \n",
       "75%       0.721157     0.575096     0.007710     0.415673     0.008047  8.464614e-03     1.004589     1.004205     0.007750     0.000000     0.009611     0.008515     0.000000  8.265552e-03  7.484257e-03     0.000000     0.000000     0.000000     0.000000     0.000000     0.009129     0.007634     0.009048     0.000000     0.009117  8.269200e-03     0.009085     0.000000     3.000000     1.000000     0.000000     4.00000     0.000000     1.000000     0.000000     6.000000     1.000000     1.0  \n",
       "max       1.295574     1.577900     2.004210     1.643043     2.009533  1.009986e+00     1.010775     1.009999    12.006965     2.884557     1.011000     1.319955     4.039000  1.509167e+00  1.007785e+00     1.009766     1.007165     1.505735     1.007997     1.502486     1.009998     1.009944     1.174753     1.747922     1.009982  1.341404e+00     4.187805     2.000000     7.000000     1.000000     1.000000     6.00000     1.000000     1.000000     1.000000     6.000000     1.000000     1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f93c6948-2884-4b14-b236-72c40f33476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from logistic import Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3066a95d-0f5e-4891-999a-583f1b0fe7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xnames = [ \"P_2\", \"D_39\", \"B_1\", \"B_2\", \"R_1\", \"S_3\", \"D_41\", \"B_3\"]\n",
    "target = 'target'\n",
    "weight = 'B_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53e608be-05a2-4478-b622-cc8b894c7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data[xnames + [target, weight]].to_csv('scorecard_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2de5cd63-b84a-46f9-a673-7f8fbcbbf7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = Logistic(data=raw_data, xnames=xnames, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6747f1db-95f1-408d-adb0-bdd9b92a47a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lr_res = lr_model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7158f80-609f-41ce-85dd-724441381fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_res.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf9c520f-b251-4d1d-8f37-afa3018bfc46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lr_backward, step = lr_model.backward(xvars=xnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4fc4d-1873-4a14-8d5c-59224fd80601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b454b76b-0b06-4c55-a0a0-3417b83b82ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8293\n",
      "Model Family:                Binomial   Df Model:                            0\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -4795.9\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       9591.7\n",
      "Time:                        14:55:23   Pearson chi2:                 8.29e+03\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):         -2.220e-16\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.0201      0.025    -41.001      0.000      -1.069      -0.971\n",
      "==============================================================================\n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t  P_2\t             \t1918.2229049218142\t     \t       0.0\t\n",
      "    \t D_39\t             \t609.2547451804684\t     \t1.6249639150697484e-134\t\n",
      "    \t  B_1\t             \t960.0078294277615\t     \t8.857272524965927e-211\t\n",
      "    \t  B_2\t             \t1850.4513279347964\t     \t       0.0\t\n",
      "    \t  R_1\t             \t1012.8574642882213\t     \t2.8809407018604544e-222\t\n",
      "    \t  S_3\t             \t780.2623657964162\t     \t1.0554677111836936e-171\t\n",
      "    \t D_41\t             \t699.5965248195968\t     \t3.6596750075313676e-154\t\n",
      "    \t  B_3\t             \t1289.181485241709\t     \t2.5365545127972156e-282\t\n",
      " \n",
      "** step 0: P_2 entered:\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8292\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2817.3\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       5634.5\n",
      "Time:                        14:55:23   Pearson chi2:                 7.41e+03\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.3794\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.2149      0.095     33.893      0.000       3.029       3.401\n",
      "P_2           -7.7885      0.178    -43.798      0.000      -8.137      -7.440\n",
      "==============================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8292\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2817.3\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       5634.5\n",
      "Time:                        14:55:23   Pearson chi2:                 7.41e+03\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.3794\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.2149      0.095     33.893      0.000       3.029       3.401\n",
      "P_2           -7.7885      0.178    -43.798      0.000      -8.137      -7.440\n",
      "==============================================================================\n",
      "**** BackWard ****\n",
      " STEP 0: No (additional) Variables met the 0.05 significance level for remove into the model\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8292\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2817.3\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       5634.5\n",
      "Time:                        14:55:23   Pearson chi2:                 7.41e+03\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.3794\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.2149      0.095     33.893      0.000       3.029       3.401\n",
      "P_2           -7.7885      0.178    -43.798      0.000      -8.137      -7.440\n",
      "==============================================================================\n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t D_39\t             \t159.9216890810357\t     \t1.1769509245830794e-36\t\n",
      "    \t  B_1\t             \t332.70978225123974\t     \t2.469450718562107e-74\t\n",
      "    \t  B_2\t             \t458.48373611943293\t     \t1.0276793839058857e-101\t\n",
      "    \t  R_1\t             \t146.21068821037605\t     \t1.1675669117423333e-33\t\n",
      "    \t  S_3\t             \t161.4822539523486\t     \t5.367879328657086e-37\t\n",
      "    \t D_41\t             \t155.70476090807193\t     \t9.821641772887185e-36\t\n",
      "    \t  B_3\t             \t346.6907159157586\t     \t2.2273719826337478e-77\t\n",
      " \n",
      "** step 1: B_2 entered:\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8291\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2573.2\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       5146.3\n",
      "Time:                        14:55:23   Pearson chi2:                 6.67e+03\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.4149\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.3790      0.098     34.439      0.000       3.187       3.571\n",
      "P_2           -6.5615      0.186    -35.323      0.000      -6.926      -6.197\n",
      "B_2           -1.9693      0.092    -21.412      0.000      -2.150      -1.789\n",
      "==============================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8291\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2573.2\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       5146.3\n",
      "Time:                        14:55:23   Pearson chi2:                 6.67e+03\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.4149\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.3790      0.098     34.439      0.000       3.187       3.571\n",
      "P_2           -6.5615      0.186    -35.323      0.000      -6.926      -6.197\n",
      "B_2           -1.9693      0.092    -21.412      0.000      -2.150      -1.789\n",
      "==============================================================================\n",
      "**** BackWard ****\n",
      " STEP 0: No (additional) Variables met the 0.05 significance level for remove into the model\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8291\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2573.2\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       5146.3\n",
      "Time:                        14:55:23   Pearson chi2:                 6.67e+03\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.4149\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.3790      0.098     34.439      0.000       3.187       3.571\n",
      "P_2           -6.5615      0.186    -35.323      0.000      -6.926      -6.197\n",
      "B_2           -1.9693      0.092    -21.412      0.000      -2.150      -1.789\n",
      "==============================================================================\n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t D_39\t             \t96.91656283585706\t     \t7.231124277510659e-23\t\n",
      "    \t  B_1\t             \t67.75159184635336\t     \t1.854470298865953e-16\t\n",
      "    \t  R_1\t             \t93.66398217205509\t     \t3.7390339939274703e-22\t\n",
      "    \t  S_3\t             \t125.77312650803236\t     \t3.4472423227802466e-29\t\n",
      "    \t D_41\t             \t96.73911509138425\t     \t7.909121284604627e-23\t\n",
      "    \t  B_3\t             \t46.07032319698615\t     \t1.1408353736675484e-11\t\n",
      " \n",
      "** step 2: S_3 entered:\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8290\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2500.6\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       5001.2\n",
      "Time:                        14:55:24   Pearson chi2:                 6.67e+03\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.4251\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.6838      0.112     23.974      0.000       2.464       2.903\n",
      "P_2           -6.2147      0.187    -33.171      0.000      -6.582      -5.848\n",
      "B_2           -1.9076      0.093    -20.441      0.000      -2.090      -1.725\n",
      "S_3            1.9962      0.178     11.215      0.000       1.647       2.345\n",
      "==============================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8290\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2500.6\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       5001.2\n",
      "Time:                        14:55:24   Pearson chi2:                 6.67e+03\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.4251\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.6838      0.112     23.974      0.000       2.464       2.903\n",
      "P_2           -6.2147      0.187    -33.171      0.000      -6.582      -5.848\n",
      "B_2           -1.9076      0.093    -20.441      0.000      -2.090      -1.725\n",
      "S_3            1.9962      0.178     11.215      0.000       1.647       2.345\n",
      "==============================================================================\n",
      "**** BackWard ****\n",
      " STEP 0: No (additional) Variables met the 0.05 significance level for remove into the model\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8290\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2500.6\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       5001.2\n",
      "Time:                        14:55:24   Pearson chi2:                 6.67e+03\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.4251\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.6838      0.112     23.974      0.000       2.464       2.903\n",
      "P_2           -6.2147      0.187    -33.171      0.000      -6.582      -5.848\n",
      "B_2           -1.9076      0.093    -20.441      0.000      -2.090      -1.725\n",
      "S_3            1.9962      0.178     11.215      0.000       1.647       2.345\n",
      "==============================================================================\n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t D_39\t             \t85.37902831602685\t     \t2.4631924713575106e-20\t\n",
      "    \t  B_1\t             \t61.42832709832155\t     \t4.591567832819611e-15\t\n",
      "    \t  R_1\t             \t74.56190148004342\t     \t5.876642210077319e-18\t\n",
      "    \t D_41\t             \t94.94834622722908\t     \t1.9541844002361585e-22\t\n",
      "    \t  B_3\t             \t59.81331972543855\t     \t1.0429511723152737e-14\t\n",
      " \n",
      "** step 3: D_41 entered:\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8289\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2438.2\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4876.4\n",
      "Time:                        14:55:24   Pearson chi2:                 6.50e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4336\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.2790      0.118     19.256      0.000       2.047       2.511\n",
      "P_2           -5.8769      0.191    -30.701      0.000      -6.252      -5.502\n",
      "B_2           -1.7510      0.095    -18.512      0.000      -1.936      -1.566\n",
      "S_3            2.0129      0.180     11.168      0.000       1.660       2.366\n",
      "D_41           1.6739      0.172      9.744      0.000       1.337       2.011\n",
      "==============================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8289\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2438.2\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4876.4\n",
      "Time:                        14:55:24   Pearson chi2:                 6.50e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4336\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.2790      0.118     19.256      0.000       2.047       2.511\n",
      "P_2           -5.8769      0.191    -30.701      0.000      -6.252      -5.502\n",
      "B_2           -1.7510      0.095    -18.512      0.000      -1.936      -1.566\n",
      "S_3            2.0129      0.180     11.168      0.000       1.660       2.366\n",
      "D_41           1.6739      0.172      9.744      0.000       1.337       2.011\n",
      "==============================================================================\n",
      "**** BackWard ****\n",
      " STEP 0: No (additional) Variables met the 0.05 significance level for remove into the model\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8289\n",
      "Model Family:                Binomial   Df Model:                            4\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2438.2\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4876.4\n",
      "Time:                        14:55:24   Pearson chi2:                 6.50e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4336\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.2790      0.118     19.256      0.000       2.047       2.511\n",
      "P_2           -5.8769      0.191    -30.701      0.000      -6.252      -5.502\n",
      "B_2           -1.7510      0.095    -18.512      0.000      -1.936      -1.566\n",
      "S_3            2.0129      0.180     11.168      0.000       1.660       2.366\n",
      "D_41           1.6739      0.172      9.744      0.000       1.337       2.011\n",
      "==============================================================================\n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t D_39\t             \t27.582428228632885\t     \t1.5054016623638394e-07\t\n",
      "    \t  B_1\t             \t65.16243330349374\t     \t6.897190466770749e-16\t\n",
      "    \t  R_1\t             \t53.16612509548683\t     \t3.064990416480048e-13\t\n",
      "    \t  B_3\t             \t59.75129354333844\t     \t1.0763440494605085e-14\t\n",
      " \n",
      "** step 4: B_1 entered:\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8288\n",
      "Model Family:                Binomial   Df Model:                            5\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2404.3\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4808.6\n",
      "Time:                        14:55:24   Pearson chi2:                 6.45e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4382\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.8472      0.129     14.334      0.000       1.595       2.100\n",
      "P_2           -5.9614      0.194    -30.685      0.000      -6.342      -5.581\n",
      "B_2           -1.2536      0.112    -11.155      0.000      -1.474      -1.033\n",
      "S_3            1.9601      0.182     10.797      0.000       1.604       2.316\n",
      "D_41           1.7495      0.176      9.936      0.000       1.404       2.095\n",
      "B_1            1.3031      0.161      8.072      0.000       0.987       1.619\n",
      "==============================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8288\n",
      "Model Family:                Binomial   Df Model:                            5\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2404.3\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4808.6\n",
      "Time:                        14:55:24   Pearson chi2:                 6.45e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4382\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.8472      0.129     14.334      0.000       1.595       2.100\n",
      "P_2           -5.9614      0.194    -30.685      0.000      -6.342      -5.581\n",
      "B_2           -1.2536      0.112    -11.155      0.000      -1.474      -1.033\n",
      "S_3            1.9601      0.182     10.797      0.000       1.604       2.316\n",
      "D_41           1.7495      0.176      9.936      0.000       1.404       2.095\n",
      "B_1            1.3031      0.161      8.072      0.000       0.987       1.619\n",
      "==============================================================================\n",
      "**** BackWard ****\n",
      " STEP 0: No (additional) Variables met the 0.05 significance level for remove into the model\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8288\n",
      "Model Family:                Binomial   Df Model:                            5\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2404.3\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4808.6\n",
      "Time:                        14:55:24   Pearson chi2:                 6.45e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4382\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.8472      0.129     14.334      0.000       1.595       2.100\n",
      "P_2           -5.9614      0.194    -30.685      0.000      -6.342      -5.581\n",
      "B_2           -1.2536      0.112    -11.155      0.000      -1.474      -1.033\n",
      "S_3            1.9601      0.182     10.797      0.000       1.604       2.316\n",
      "D_41           1.7495      0.176      9.936      0.000       1.404       2.095\n",
      "B_1            1.3031      0.161      8.072      0.000       0.987       1.619\n",
      "==============================================================================\n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t D_39\t             \t25.64375917989557\t     \t4.1062131132783367e-07\t\n",
      "    \t  R_1\t             \t51.55312877515025\t     \t6.96855465125489e-13\t\n",
      "    \t  B_3\t             \t18.56441749485286\t     \t1.6425813832600143e-05\t\n",
      " \n",
      "** step 5: R_1 entered:\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8287\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2376.1\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4752.2\n",
      "Time:                        14:55:24   Pearson chi2:                 6.76e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4421\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5193      0.137     11.130      0.000       1.252       1.787\n",
      "P_2           -5.5516      0.201    -27.636      0.000      -5.945      -5.158\n",
      "B_2           -1.1969      0.113    -10.553      0.000      -1.419      -0.975\n",
      "S_3            1.8579      0.183     10.143      0.000       1.499       2.217\n",
      "D_41           1.6362      0.179      9.153      0.000       1.286       1.987\n",
      "B_1            1.2986      0.163      7.975      0.000       0.979       1.618\n",
      "R_1            1.1780      0.164      7.180      0.000       0.856       1.500\n",
      "==============================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8287\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2376.1\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4752.2\n",
      "Time:                        14:55:24   Pearson chi2:                 6.76e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4421\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5193      0.137     11.130      0.000       1.252       1.787\n",
      "P_2           -5.5516      0.201    -27.636      0.000      -5.945      -5.158\n",
      "B_2           -1.1969      0.113    -10.553      0.000      -1.419      -0.975\n",
      "S_3            1.8579      0.183     10.143      0.000       1.499       2.217\n",
      "D_41           1.6362      0.179      9.153      0.000       1.286       1.987\n",
      "B_1            1.2986      0.163      7.975      0.000       0.979       1.618\n",
      "R_1            1.1780      0.164      7.180      0.000       0.856       1.500\n",
      "==============================================================================\n",
      "**** BackWard ****\n",
      " STEP 0: No (additional) Variables met the 0.05 significance level for remove into the model\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8287\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2376.1\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4752.2\n",
      "Time:                        14:55:24   Pearson chi2:                 6.76e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4421\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.5193      0.137     11.130      0.000       1.252       1.787\n",
      "P_2           -5.5516      0.201    -27.636      0.000      -5.945      -5.158\n",
      "B_2           -1.1969      0.113    -10.553      0.000      -1.419      -0.975\n",
      "S_3            1.8579      0.183     10.143      0.000       1.499       2.217\n",
      "D_41           1.6362      0.179      9.153      0.000       1.286       1.987\n",
      "B_1            1.2986      0.163      7.975      0.000       0.979       1.618\n",
      "R_1            1.1780      0.164      7.180      0.000       0.856       1.500\n",
      "==============================================================================\n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t D_39\t             \t19.726077881262746\t     \t8.937342563388047e-06\t\n",
      "    \t  B_3\t             \t17.609702065978556\t     \t2.7120122780971836e-05\t\n",
      " \n",
      "** step 6: D_39 entered:\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8286\n",
      "Model Family:                Binomial   Df Model:                            7\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2365.8\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4731.6\n",
      "Time:                        14:55:24   Pearson chi2:                 6.65e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4434\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.4588      0.137     10.629      0.000       1.190       1.728\n",
      "P_2           -5.5724      0.201    -27.668      0.000      -5.967      -5.178\n",
      "B_2           -1.1701      0.114    -10.304      0.000      -1.393      -0.948\n",
      "S_3            1.8166      0.184      9.891      0.000       1.457       2.177\n",
      "D_41           1.2628      0.196      6.450      0.000       0.879       1.647\n",
      "B_1            1.2857      0.163      7.880      0.000       0.966       1.606\n",
      "R_1            1.1209      0.165      6.780      0.000       0.797       1.445\n",
      "D_39           0.5959      0.134      4.441      0.000       0.333       0.859\n",
      "==============================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8286\n",
      "Model Family:                Binomial   Df Model:                            7\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2365.8\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4731.6\n",
      "Time:                        14:55:24   Pearson chi2:                 6.65e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4434\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.4588      0.137     10.629      0.000       1.190       1.728\n",
      "P_2           -5.5724      0.201    -27.668      0.000      -5.967      -5.178\n",
      "B_2           -1.1701      0.114    -10.304      0.000      -1.393      -0.948\n",
      "S_3            1.8166      0.184      9.891      0.000       1.457       2.177\n",
      "D_41           1.2628      0.196      6.450      0.000       0.879       1.647\n",
      "B_1            1.2857      0.163      7.880      0.000       0.966       1.606\n",
      "R_1            1.1209      0.165      6.780      0.000       0.797       1.445\n",
      "D_39           0.5959      0.134      4.441      0.000       0.333       0.859\n",
      "==============================================================================\n",
      "**** BackWard ****\n",
      " STEP 0: No (additional) Variables met the 0.05 significance level for remove into the model\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8286\n",
      "Model Family:                Binomial   Df Model:                            7\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2365.8\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4731.6\n",
      "Time:                        14:55:24   Pearson chi2:                 6.65e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4434\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.4588      0.137     10.629      0.000       1.190       1.728\n",
      "P_2           -5.5724      0.201    -27.668      0.000      -5.967      -5.178\n",
      "B_2           -1.1701      0.114    -10.304      0.000      -1.393      -0.948\n",
      "S_3            1.8166      0.184      9.891      0.000       1.457       2.177\n",
      "D_41           1.2628      0.196      6.450      0.000       0.879       1.647\n",
      "B_1            1.2857      0.163      7.880      0.000       0.966       1.606\n",
      "R_1            1.1209      0.165      6.780      0.000       0.797       1.445\n",
      "D_39           0.5959      0.134      4.441      0.000       0.333       0.859\n",
      "==============================================================================\n",
      "              Analysis of Variables Eligible for Entry  \n",
      "==============================================================================\n",
      "\tvariable\t \tWald Chi-square\t \tPr>ChiSq\t\n",
      "    \t  B_3\t             \t18.86663685744107\t     \t1.4018309777449191e-05\t\n",
      " \n",
      "** step 7: B_3 entered:\n",
      "\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                 8294\n",
      "Model:                            GLM   Df Residuals:                     8285\n",
      "Model Family:                Binomial   Df Model:                            8\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2356.3\n",
      "Date:                Fri, 05 Aug 2022   Deviance:                       4712.6\n",
      "Time:                        14:55:25   Pearson chi2:                 6.61e+03\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.4447\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1904      0.150      7.920      0.000       0.896       1.485\n",
      "P_2           -5.4990      0.202    -27.229      0.000      -5.895      -5.103\n",
      "B_2           -0.9357      0.126     -7.421      0.000      -1.183      -0.689\n",
      "S_3            1.9038      0.185     10.274      0.000       1.541       2.267\n",
      "D_41           1.2414      0.197      6.298      0.000       0.855       1.628\n",
      "B_1            0.8871      0.187      4.746      0.000       0.521       1.253\n",
      "R_1            1.1073      0.166      6.688      0.000       0.783       1.432\n",
      "D_39           0.6153      0.135      4.574      0.000       0.352       0.879\n",
      "B_3            0.8275      0.191      4.344      0.000       0.454       1.201\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "lr_res = lr_model.stepwise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3c2ea-b3f8-46b4-a88f-a7adeb9a2bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed17e5-f013-4dae-9b3a-6b774adba04e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3b9d5-7049-488c-b738-0f6d1ccce24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862360a-5eda-4732-bb2e-dfdb529361b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade5d312-fd01-44d8-83a1-276c35c4a11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
